{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ad2be3",
   "metadata": {},
   "source": [
    "### Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35819200",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     23\u001b[39m FILEPATH = \u001b[33m\"\u001b[39m\u001b[33m/mnt/data/Data Historis Imbal Hasil Obligasi Indonesia 10 Tahun (7).xlsx\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Process Indonesian 10Y government bond yield history from:\n",
    "  /mnt/data/Data Historis Imbal Hasil Obligasi Indonesia 10 Tahun (7).xlsx\n",
    "\n",
    "What this script does:\n",
    "1) Loads the Excel, auto-detects the date and yield columns (robust to header names).\n",
    "2) Cleans the series (parses dates, converts yield to numeric, sorts, drops NA).\n",
    "3) Computes rate-change shocks:\n",
    "   - Daily (or native frequency) Δy\n",
    "   - Monthly Δy (end-of-month)\n",
    "   - Percentile shocks (e.g., 95%, 99% up; 5%, 1% down)\n",
    "   - Worst window shocks (e.g., worst 1M / 3M change)\n",
    "4) Prints a concise summary for use in stress-test design.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "FILEPATH = \"/mnt/data/Data Historis Imbal Hasil Obligasi Indonesia 10 Tahun (7).xlsx\"\n",
    "\n",
    "\n",
    "def _read_first_nonempty_sheet(path: str) -> pd.DataFrame:\n",
    "    xls = pd.ExcelFile(path)\n",
    "    for sh in xls.sheet_names:\n",
    "        df = pd.read_excel(path, sheet_name=sh)\n",
    "        # consider \"nonempty\" if at least a few non-null cells exist\n",
    "        if df.size > 0 and df.notna().sum().sum() > 10:\n",
    "            df[\"_sheet_name\"] = sh\n",
    "            return df\n",
    "    raise ValueError(\"No non-empty sheet found in the Excel file.\")\n",
    "\n",
    "\n",
    "def _guess_date_col(df: pd.DataFrame) -> str:\n",
    "    # Prefer columns with typical date keywords\n",
    "    candidates = []\n",
    "    for c in df.columns:\n",
    "        if not isinstance(c, str):\n",
    "            continue\n",
    "        cl = c.lower()\n",
    "        if any(k in cl for k in [\"date\", \"tanggal\", \"time\", \"periode\", \"period\"]):\n",
    "            candidates.append(c)\n",
    "    if candidates:\n",
    "        return candidates[0]\n",
    "\n",
    "    # Otherwise, choose the column with the highest date-parsing success rate\n",
    "    best_col = None\n",
    "    best_score = -1\n",
    "    for c in df.columns:\n",
    "        if c == \"_sheet_name\":\n",
    "            continue\n",
    "        parsed = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=True)\n",
    "        score = parsed.notna().mean()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_col = c\n",
    "    if best_col is None or best_score < 0.2:\n",
    "        raise ValueError(\"Could not confidently detect a date column.\")\n",
    "    return best_col\n",
    "\n",
    "\n",
    "def _guess_yield_col(df: pd.DataFrame, date_col: str) -> str:\n",
    "    # Prefer columns with yield keywords\n",
    "    yield_kw = [\"yield\", \"imbal\", \"hasil\", \"yld\", \"rate\", \"kupon\", \"return\"]\n",
    "    candidates = []\n",
    "    for c in df.columns:\n",
    "        if c in [date_col, \"_sheet_name\"]:\n",
    "            continue\n",
    "        if isinstance(c, str) and any(k in c.lower() for k in yield_kw):\n",
    "            candidates.append(c)\n",
    "    if candidates:\n",
    "        return candidates[0]\n",
    "\n",
    "    # Otherwise, choose the \"most numeric\" column (after coercion)\n",
    "    best_col = None\n",
    "    best_score = -1\n",
    "    for c in df.columns:\n",
    "        if c in [date_col, \"_sheet_name\"]:\n",
    "            continue\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        score = s.notna().mean()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_col = c\n",
    "    if best_col is None or best_score < 0.2:\n",
    "        raise ValueError(\"Could not confidently detect a yield column.\")\n",
    "    return best_col\n",
    "\n",
    "\n",
    "def _to_numeric_yield(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Robust numeric conversion:\n",
    "    - Handles '7,25' vs '7.25'\n",
    "    - Handles percent strings like '7.25%' or '7,25 %'\n",
    "    \"\"\"\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = s.replace({\"\": np.nan, \"nan\": np.nan, \"None\": np.nan, \"-\": np.nan})\n",
    "\n",
    "    # Remove percent signs and spaces\n",
    "    s = s.str.replace(\"%\", \"\", regex=False).str.replace(\" \", \"\", regex=False)\n",
    "\n",
    "    # Convert comma decimal to dot decimal where appropriate\n",
    "    # e.g., '7,25' -> '7.25'\n",
    "    s = s.str.replace(r\"(?<=\\d),(?=\\d)\", \".\", regex=True)\n",
    "\n",
    "    out = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def prepare_yield_series(path: str) -> pd.DataFrame:\n",
    "    raw = _read_first_nonempty_sheet(path)\n",
    "    sheet = raw[\"_sheet_name\"].iloc[0] if \"_sheet_name\" in raw.columns else \"unknown\"\n",
    "\n",
    "    date_col = _guess_date_col(raw)\n",
    "    y_col = _guess_yield_col(raw, date_col)\n",
    "\n",
    "    df = raw[[date_col, y_col]].copy()\n",
    "    df.columns = [\"date\", \"yield_raw\"]\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\", dayfirst=True)\n",
    "    df[\"y\"] = _to_numeric_yield(df[\"yield_raw\"])\n",
    "\n",
    "    df = df.dropna(subset=[\"date\", \"y\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    # Heuristic: if yields look like 0.07 rather than 7.0, scale to percent.\n",
    "    # We'll keep both: y_pct (in %) and y_dec (in decimal)\n",
    "    y_med = df[\"y\"].median()\n",
    "    if y_med < 1.0:\n",
    "        df[\"y_dec\"] = df[\"y\"]\n",
    "        df[\"y_pct\"] = df[\"y\"] * 100.0\n",
    "    else:\n",
    "        df[\"y_pct\"] = df[\"y\"]\n",
    "        df[\"y_dec\"] = df[\"y\"] / 100.0\n",
    "\n",
    "    df.attrs[\"sheet_name\"] = sheet\n",
    "    df.attrs[\"date_col_detected\"] = date_col\n",
    "    df.attrs[\"yield_col_detected\"] = y_col\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_shocks(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Returns shocks in basis points (bps) for convenience.\n",
    "    - Δy computed on y_dec (decimal), then converted to bps: 1bp = 0.0001\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "\n",
    "    # Native frequency changes\n",
    "    df = df.copy()\n",
    "    df[\"dy\"] = df[\"y_dec\"].diff()\n",
    "    dy = df[\"dy\"].dropna()\n",
    "\n",
    "    out[\"native\"] = {\n",
    "        \"count\": int(dy.shape[0]),\n",
    "        \"p95_up_bps\": float(dy.quantile(0.95) / 1e-4),\n",
    "        \"p99_up_bps\": float(dy.quantile(0.99) / 1e-4),\n",
    "        \"p05_down_bps\": float(dy.quantile(0.05) / 1e-4),\n",
    "        \"p01_down_bps\": float(dy.quantile(0.01) / 1e-4),\n",
    "        \"max_up_bps\": float(dy.max() / 1e-4),\n",
    "        \"max_down_bps\": float(dy.min() / 1e-4),\n",
    "    }\n",
    "\n",
    "    # Monthly end-of-month series and changes\n",
    "    m = (\n",
    "        df.set_index(\"date\")[[\"y_dec\"]]\n",
    "        .resample(\"M\")\n",
    "        .last()\n",
    "        .dropna()\n",
    "        .rename(columns={\"y_dec\": \"y_dec_m\"})\n",
    "    )\n",
    "    m[\"dy_m\"] = m[\"y_dec_m\"].diff()\n",
    "    dy_m = m[\"dy_m\"].dropna()\n",
    "\n",
    "    out[\"monthly\"] = {\n",
    "        \"count\": int(dy_m.shape[0]),\n",
    "        \"p95_up_bps\": float(dy_m.quantile(0.95) / 1e-4),\n",
    "        \"p99_up_bps\": float(dy_m.quantile(0.99) / 1e-4),\n",
    "        \"p05_down_bps\": float(dy_m.quantile(0.05) / 1e-4),\n",
    "        \"p01_down_bps\": float(dy_m.quantile(0.01) / 1e-4),\n",
    "        \"max_up_bps\": float(dy_m.max() / 1e-4),\n",
    "        \"max_down_bps\": float(dy_m.min() / 1e-4),\n",
    "    }\n",
    "\n",
    "    # Worst window shocks (e.g., 1M and 3M) using monthly data\n",
    "    # Δ over k months: y(t) - y(t-k)\n",
    "    for k in [1, 3, 6, 12]:\n",
    "        dk = m[\"y_dec_m\"].diff(k).dropna()\n",
    "        out[f\"worst_{k}m\"] = {\n",
    "            \"worst_up_bps\": float(dk.max() / 1e-4),\n",
    "            \"worst_down_bps\": float(dk.min() / 1e-4),\n",
    "        }\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def print_summary(df: pd.DataFrame, shocks: dict) -> None:\n",
    "    sheet = df.attrs.get(\"sheet_name\", \"unknown\")\n",
    "    print(\"=== DATASET SUMMARY ===\")\n",
    "    print(f\"Sheet used           : {sheet}\")\n",
    "    print(f\"Detected date col    : {df.attrs.get('date_col_detected')}\")\n",
    "    print(f\"Detected yield col   : {df.attrs.get('yield_col_detected')}\")\n",
    "    print(f\"Date range           : {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "    print(f\"Observations         : {len(df):,}\")\n",
    "    print(f\"Yield (median, %)    : {df['y_pct'].median():.3f}\")\n",
    "\n",
    "    print(\"\\n=== SHOCKS (BASIS POINTS) ===\")\n",
    "    for block in [\"native\", \"monthly\"]:\n",
    "        b = shocks[block]\n",
    "        print(f\"\\n[{block.upper()} Δy]\")\n",
    "        print(f\"  Count        : {b['count']:,}\")\n",
    "        print(f\"  Up 95% / 99% : {b['p95_up_bps']:.1f} bps / {b['p99_up_bps']:.1f} bps\")\n",
    "        print(f\"  Dn 5% / 1%   : {b['p05_down_bps']:.1f} bps / {b['p01_down_bps']:.1f} bps\")\n",
    "        print(f\"  Max up/down  : {b['max_up_bps']:.1f} bps / {b['max_down_bps']:.1f} bps\")\n",
    "\n",
    "    for k in [1, 3, 6, 12]:\n",
    "        b = shocks[f\"worst_{k}m\"]\n",
    "        print(f\"\\n[WORST {k}M WINDOW (monthly)]\")\n",
    "        print(f\"  Worst up     : {b['worst_up_bps']:.1f} bps\")\n",
    "        print(f\"  Worst down   : {b['worst_down_bps']:.1f} bps\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = prepare_yield_series(FILEPATH)\n",
    "    shocks = compute_shocks(df)\n",
    "    print_summary(df, shocks)\n",
    "\n",
    "    # Optional: export cleaned series for audit trail\n",
    "    out_csv = \"/mnt/data/indo_10y_yield_clean.csv\"\n",
    "    df[[\"date\", \"y_pct\", \"y_dec\"]].to_csv(out_csv, index=False)\n",
    "    print(f\"\\nSaved cleaned series to: {out_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
